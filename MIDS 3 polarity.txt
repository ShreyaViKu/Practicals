
MIDS 3
# Importing required libraries
import pandas as pd                    # For data handling
import numpy as np                     # For numerical operations
import re                              # For regular expressions (used in cleaning)
import string                          # For punctuation removal
import seaborn as sns                  # For visualization
import matplotlib.pyplot as plt        # For plotting graphs

# Importing ML Tools
from sklearn.feature_extraction.text import TfidfVectorizer  # Converts text to numeric features
from sklearn.linear_model import LogisticRegression          # Classification model
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # For evaluation

# For uploading CSV file manually
from google.colab import files
uploaded = files.upload()

# Replace with the actual filename after upload
filename = list(uploaded.keys())[0]
train_df = pd.read_csv(filename)

from google.colab import files
uploaded = files.upload()

# Replace with the actual filename after upload
filename = list(uploaded.keys())[0]
test_df = pd.read_csv(filename)

# Preview the training data
print(" Training Data Preview:\n", train_df.head())
print("\n Column Names:", train_df.columns)

# Step 1: Clean the data by removing rows with missing text or labels
train_df.dropna(subset=["Content", "Label"], inplace=True)
test_df.dropna(subset=["Content", "Label"], inplace=True)

# Step 2: Define a function to clean the text
def clean_text(text):
    text = re.sub(r"http\S+", "", text)                            # Remove URLs
    text = re.sub(r"@\w+", "", text)                               # Remove @mentions
    text = re.sub(r"#\w+", "", text)                               # Remove hashtags
    text = re.sub(r"\d+", "", text)                                # Remove digits
    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation
    return text.lower().strip()                                    # Lowercase and remove spaces

# Step 3: Apply the cleaning function to both train and test data
train_df["clean_text"] = train_df["Content"].apply(clean_text)
test_df["clean_text"] = test_df["Content"].apply(clean_text)

# Step 4: Convert text data into numerical form using TF-IDF Vectorizer
vectorizer = TfidfVectorizer(stop_words='english', max_features=3000)  # Ignore common words
X_train = vectorizer.fit_transform(train_df["clean_text"])              # Fit and transform train text
X_test = vectorizer.transform(test_df["clean_text"])                    # Only transform test text

# Step 5: Define the target variables (labels)
y_train = train_df["Label"]   # Actual sentiment (positive/negative) for training
y_test = test_df["Label"]     # Actual sentiment for testing

# Step 6: Train the Logistic Regression Model
model = LogisticRegression()
model.fit(X_train, y_train)

# Step 7: Predict sentiments on the test data
y_pred = model.predict(X_test)

# Step 8: Evaluate the Model
print(f"\n Model Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\n")
print(" Classification Report:\n", classification_report(y_test, y_pred))

#  Step 9: Confusion Matrix Visualization
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="YlGnBu",
            xticklabels=model.classes_, yticklabels=model.classes_)
plt.title("Confusion Matrix - Sentiment Classification")
plt.xlabel("Predicted Sentiment")
plt.ylabel("Actual Sentiment")
plt.show()


